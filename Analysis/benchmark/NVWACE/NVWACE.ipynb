{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b91453d-d91a-4bb0-af9d-b8658b273331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from pyfaidx import Fasta\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc27d3a-f925-42fd-99d4-51f01a614653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "def train(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, \n",
    "          learning_rate: float, num_epochs: int, device: torch.device):\n",
    "    \"\"\"\n",
    "    训练模型的主循环。\n",
    "\n",
    "    参数:\n",
    "    model (nn.Module): 要训练的模型。\n",
    "    train_loader (DataLoader): 训练数据的 DataLoader。\n",
    "    val_loader (DataLoader): 验证数据的 DataLoader。\n",
    "    learning_rate (float): 初始学习率。\n",
    "    num_epochs (int): 训练的周期数。\n",
    "    device (torch.device): 训练设备 ('cuda' 或 'cpu')。\n",
    "    \"\"\"\n",
    "    # 1. 初始化优化器和损失函数\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # 使用CrossEntropyLoss处理one-hot标签\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    # 2. 将模型移动到目标设备\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"Starting training for {num_epochs} epochs on device: {device}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- 训练阶段 ---\n",
    "        model.train() # 设置为训练模式\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # 使用 tqdm 封装 DataLoader 以显示进度\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\")\n",
    "        \n",
    "        for batch_idx, (seq, target, ct) in enumerate(train_loop):\n",
    "            # 1. 数据移动到设备\n",
    "            # DNA独热编码 (B, L, 4) -> (B, 4, L)\n",
    "            seq= seq.float().permute(0, 2, 1).to(device) \n",
    "            # target已经是one-hot形式 (B, 2)，不需要转换\n",
    "            target = target.to(device)  # 保持 (B, 2) 形状\n",
    "            \n",
    "            # 2. 前向传播\n",
    "            output = model(seq,ct)\n",
    "            # 3. 计算损失 - 使用CrossEntropyLoss处理one-hot标签\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            # 4. 反向传播和优化\n",
    "            optimizer.zero_grad() # 梯度清零\n",
    "            loss.backward() # 反向传播\n",
    "            optimizer.step() # 更新参数\n",
    "\n",
    "            train_loss += loss.item() * len(seq)\n",
    "            train_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # --- 验证阶段 ---\n",
    "        model.eval() # 设置为评估模式\n",
    "        val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        with torch.no_grad(): # 禁用梯度计算\n",
    "            for seq, target, ct in val_loader:\n",
    "                seq = seq.float().permute(0, 2, 1).to(device)\n",
    "                target = target.to(device)  # 保持 (B, 2) 形状\n",
    "\n",
    "                output = model(seq, ct)\n",
    "                loss = loss_fn(output, target)\n",
    "                val_loss += loss.item() * len(seq)\n",
    "\n",
    "                # 计算准确率 - 使用argmax获取预测类别\n",
    "                # output形状 (B, 2)，取最大值的索引作为预测类别\n",
    "                predicted_classes = torch.where(output>0.5, 1, 0) \n",
    "                # target形状 (B, 2)，取最大值的索引作为真实类别\n",
    "                true_classes = target\n",
    "                correct_predictions += (predicted_classes == true_classes).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = correct_predictions / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "\n",
    "def predict(model: nn.Module, data_loader: DataLoader, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    对给定数据集进行预测。\n",
    "\n",
    "    参数:\n",
    "    model (nn.Module): 训练好的 Sei 模型。\n",
    "    data_loader (DataLoader): 待预测数据的 DataLoader。\n",
    "    device (torch.device): 预测设备 ('cuda' 或 'cpu')。\n",
    "\n",
    "    返回:\n",
    "    torch.Tensor: 模型的输出 (Sigmoid激活后的概率值)。\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval() # 设置为评估模式\n",
    "    all_predictions = []\n",
    "\n",
    "    print(\"Starting prediction...\")\n",
    "    \n",
    "    with torch.no_grad(): # 禁用梯度计算\n",
    "        for SEQ, _, CT in tqdm(data_loader, desc=\"Predicting\"):\n",
    "            # 前向传播\n",
    "            SEQ = SEQ.float().permute(0, 2, 1).to(device)\n",
    "            output = model(SEQ, CT)\n",
    "            all_predictions.append(output.cpu())\n",
    "\n",
    "    # 拼接所有批次的预测结果\n",
    "    return torch.cat(all_predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e28f44-efa4-433e-9c16-c3fe4c97b307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, celltypes, vocab=None):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.celltypes = celltypes\n",
    "        \n",
    "        # 如果你没有提前定义字典，这里自动创建一个简单的碱基映射\n",
    "        if vocab is None:\n",
    "            vocab = {'A': 0, 'C': 1, 'G': 2, 'T': 3, 'N': 4}\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq   = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        ct    = self.celltypes[idx]\n",
    "        return seq, label, ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83720fa6-3d75-4e43-868f-1666e3aa3ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "__all__ = ['ResNeXt', 'resnext18', 'resnext34', 'resnext50', 'resnext101','resnext152']\n",
    "\n",
    "def conv1x3(in_planes, out_planes, stride=1, groups=32):\n",
    "    \"\"\"1x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=(1,3), stride=stride,\n",
    "                     padding=(0,1), bias=False, groups=groups)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, num_group=32):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv1x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv1x3(planes, planes, groups=num_group)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, num_group=32):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes*2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes*2)\n",
    "        self.conv2 = nn.Conv2d(planes*2, planes*2, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False, groups=num_group)\n",
    "        self.bn2 = nn.BatchNorm2d(planes*2)\n",
    "        self.conv3 = nn.Conv2d(planes*2, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        use_bias: bool = True,\n",
    "        batch_norm: bool = True,\n",
    "        dropout: float = 0.2,\n",
    "        activation_fn: Callable = nn.GELU(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(in_features, out_features, bias=use_bias)\n",
    "        self.batch_norm = (\n",
    "            nn.BatchNorm1d(out_features) if batch_norm else nn.Identity()\n",
    "        )\n",
    "        self.activation_fn = activation_fn\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.dense(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation_fn(x)\n",
    "        return x\n",
    "\n",
    "class ResNeXt(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, num_group=32):\n",
    "        self.inplanes = 128\n",
    "        super(ResNeXt, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 128, kernel_size=(1,7), stride=1, padding=(0,3),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        # self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 128, layers[0], num_group)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[1], num_group, stride=2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[2], num_group, stride=2)\n",
    "        self.layer4 = self._make_layer(block, 1024, layers[3], num_group, stride=2)\n",
    "        \n",
    "        self.bottleneck = DenseLayer(\n",
    "            in_features= 1024 * block.expansion,\n",
    "            out_features= 32,\n",
    "            use_bias=True,\n",
    "            batch_norm=True,\n",
    "            dropout=0.2,\n",
    "            activation_fn=nn.Identity(),\n",
    "        )\n",
    "        self.fc1 = DenseLayer(\n",
    "            in_features= 32 * block.expansion,\n",
    "            out_features= num_classes,\n",
    "            use_bias=True,\n",
    "            batch_norm=True,\n",
    "            dropout=0.2,\n",
    "            activation_fn=nn.Identity(),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "          #  nn.Linear(32, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, num_group, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, num_group=num_group))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, num_group=num_group))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "\n",
    "    def save(self, fname=None):\n",
    "        if fname is None:\n",
    "            fname = time.strftime(\"model\" + '%m%d_%H:%M:%S.pth')\n",
    "        torch.save(self.state_dict(), fname)\n",
    "        return fname\n",
    "\n",
    "\n",
    "    def load(self, fpath):\n",
    "        self.load_state_dict(torch.load(fpath))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.bottleneck(x)\n",
    "        x=x.flatten(1)\n",
    "        x = self.fc1(x)\n",
    "        x=x.flatten(1)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnext18( **kwargs):\n",
    "    \"\"\"Constructs a ResNeXt-18 model.\n",
    "    \"\"\"\n",
    "    model = ResNeXt(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnext34(**kwargs):\n",
    "    \"\"\"Constructs a ResNeXt-34 model.\n",
    "    \"\"\"\n",
    "    model = ResNeXt(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnext50(**kwargs):\n",
    "    \"\"\"Constructs a ResNeXt-50 model.\n",
    "    \"\"\"\n",
    "    model = ResNeXt(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnext101(**kwargs):\n",
    "    \"\"\"Constructs a ResNeXt-101 model.\n",
    "    \"\"\"\n",
    "    model = ResNeXt(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnext152(**kwargs):\n",
    "    \"\"\"Constructs a ResNeXt-152 model.\n",
    "    \"\"\"\n",
    "    model = ResNeXt(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    return model\n",
    "\n",
    "class CrossCellLineModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,base_model,cell_type_num=32,device='cuda:1'):\n",
    "        super().__init__()\n",
    "        self.base_model = nn.ModuleList([base_model(num_classes=1) for _ in range(cell_type_num)])\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self,seq,ct):\n",
    "        batch_size = seq.shape[0]\n",
    "        outputs = torch.zeros(batch_size, device=self.device)\n",
    "\n",
    "        # 为每个模型收集属于它的样本\n",
    "        for model_idx in range(len(self.base_model)):\n",
    "            # 找出使用当前模型的样本索引\n",
    "            mask = (ct == model_idx)\n",
    "            if mask.sum() > 0:  # 有样本使用这个模型\n",
    "                # 批量处理所有使用同一模型的样本\n",
    "                batch_seq = seq[mask]\n",
    "                batch_output = self.base_model[model_idx](batch_seq)\n",
    "                outputs[mask] = batch_output.flatten()\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de01b652-649c-4ff3-b9de-2c6fdf2d1152",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43774/43774 [00:30<00:00, 1456.99it/s]\n",
      "100%|██████████| 5477/5477 [00:03<00:00, 1447.85it/s]\n",
      "100%|██████████| 5474/5474 [00:03<00:00, 1433.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('/cluster2/huanglab/liquan/data/eSCREEN/Demo/data/demo_dataset.pkl','rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "trainset = data['Trainset']\n",
    "trainset = trainset[ trainset['cell_line']!='A549' ].reset_index(drop=True)\n",
    "testset  = data['Testset']\n",
    "testset  = testset[ testset['cell_line']!='A549' ].reset_index(drop=True)\n",
    "validset = data['Validset']\n",
    "validset = validset[ validset['cell_line']!='A549' ].reset_index(drop=True)\n",
    "\n",
    "base_to_array={'A':[1,0,0,0],'C':[0,1,0,0],'G':[0,0,1,0],'T':[0,0,0,1],'N':[0,0,0,0]}\n",
    "cell_type_dict = {'K562':0,'HepG2':1,'hPSC':2,'A549':3}\n",
    "\n",
    "def one_hot(seq):return np.stack( np.array( [base_to_array[a] for a in seq] ) )\n",
    "\n",
    "trainset['one hot'] = None\n",
    "for i,row in tqdm(trainset.iterrows(),total=len(trainset)):\n",
    "    trainset.at[i,'one hot'] = one_hot(row['sequence'])\n",
    "train_ohe = np.stack(trainset['one hot'])\n",
    "testset['one hot'] = None\n",
    "for i,row in tqdm(testset.iterrows(),total=len(testset)):\n",
    "    testset.at[i,'one hot'] = one_hot(row['sequence'])\n",
    "test_ohe = np.stack(testset['one hot'])\n",
    "validset['one hot'] = None\n",
    "for i,row in tqdm(validset.iterrows(),total=len(validset)):\n",
    "    validset.at[i,'one hot'] = one_hot(row['sequence'])\n",
    "valid_ohe = np.stack(validset['one hot'])\n",
    "\n",
    "_X_train_ = torch.tensor(train_ohe)\n",
    "X_train = torch.zeros(_X_train_.size(0),512,4)\n",
    "X_train[:,6:506,:] = _X_train_\n",
    "Y_train = torch.tensor(trainset['label'].values,dtype=torch.float)\n",
    "Z_train = torch.tensor(np.stack([cell_type_dict[ct] for ct in trainset['cell_line'].values])).int()\n",
    "\n",
    "_X_test_ = torch.tensor(test_ohe)\n",
    "X_test = torch.zeros(_X_test_.size(0),512,4)\n",
    "X_test[:,6:506,:] = _X_test_\n",
    "Y_test = torch.tensor(testset['label'].values,dtype=torch.float)\n",
    "Z_test = torch.tensor(np.stack([cell_type_dict[ct] for ct in testset['cell_line'].values])).int()\n",
    "\n",
    "_X_valid_ = torch.tensor(valid_ohe)\n",
    "X_valid = torch.zeros(_X_valid_.size(0),512,4)\n",
    "X_valid[:,6:506,:] = _X_valid_\n",
    "Y_valid = torch.tensor(validset['label'].values,dtype=torch.float)\n",
    "Z_valid = torch.tensor(np.stack([cell_type_dict[ct] for ct in validset['cell_line'].values])).int()\n",
    "\n",
    "train_data   = SeqDataset(X_train, Y_train, Z_train)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "test_data   = SeqDataset(X_test, Y_test, Z_test)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "valid_data   = SeqDataset(X_valid, Y_valid, Z_valid)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4fd4c8f-af4a-4536-a37d-8f5772f305fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 20 epochs on device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 (Train): 100%|██████████| 342/342 [00:33<00:00, 10.24it/s, loss=0.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "  Train Loss: 0.6298\n",
      "  Validation Loss: 0.6075, Accuracy: 0.6947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.48it/s, loss=0.541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "  Train Loss: 0.5788\n",
      "  Validation Loss: 0.5888, Accuracy: 0.7026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.48it/s, loss=0.524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "  Train Loss: 0.5314\n",
      "  Validation Loss: 0.5932, Accuracy: 0.6911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.51it/s, loss=0.509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary:\n",
      "  Train Loss: 0.4899\n",
      "  Validation Loss: 0.6436, Accuracy: 0.6533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.49it/s, loss=0.51] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Summary:\n",
      "  Train Loss: 0.4535\n",
      "  Validation Loss: 0.6248, Accuracy: 0.6573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.48it/s, loss=0.429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Summary:\n",
      "  Train Loss: 0.4242\n",
      "  Validation Loss: 0.6349, Accuracy: 0.6354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.48it/s, loss=0.379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Summary:\n",
      "  Train Loss: 0.3964\n",
      "  Validation Loss: 0.6630, Accuracy: 0.6275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.45it/s, loss=0.407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Summary:\n",
      "  Train Loss: 0.3780\n",
      "  Validation Loss: 0.6083, Accuracy: 0.6703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.55it/s, loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Summary:\n",
      "  Train Loss: 0.3628\n",
      "  Validation Loss: 0.6298, Accuracy: 0.6515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.53it/s, loss=0.365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Summary:\n",
      "  Train Loss: 0.3495\n",
      "  Validation Loss: 0.6425, Accuracy: 0.6476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.53it/s, loss=0.364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 Summary:\n",
      "  Train Loss: 0.3418\n",
      "  Validation Loss: 0.6129, Accuracy: 0.6706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.47it/s, loss=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12 Summary:\n",
      "  Train Loss: 0.3337\n",
      "  Validation Loss: 0.6271, Accuracy: 0.6546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.53it/s, loss=0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13 Summary:\n",
      "  Train Loss: 0.3273\n",
      "  Validation Loss: 0.6943, Accuracy: 0.6129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.51it/s, loss=0.318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 Summary:\n",
      "  Train Loss: 0.3208\n",
      "  Validation Loss: 0.6427, Accuracy: 0.6485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.51it/s, loss=0.318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 Summary:\n",
      "  Train Loss: 0.3135\n",
      "  Validation Loss: 0.6490, Accuracy: 0.6644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.50it/s, loss=0.298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 Summary:\n",
      "  Train Loss: 0.3110\n",
      "  Validation Loss: 0.6614, Accuracy: 0.6370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.43it/s, loss=0.31] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17 Summary:\n",
      "  Train Loss: 0.3073\n",
      "  Validation Loss: 0.7744, Accuracy: 0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.49it/s, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18 Summary:\n",
      "  Train Loss: 0.3015\n",
      "  Validation Loss: 0.6076, Accuracy: 0.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.50it/s, loss=0.283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19 Summary:\n",
      "  Train Loss: 0.2953\n",
      "  Validation Loss: 0.6176, Accuracy: 0.6624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 (Train): 100%|██████████| 342/342 [00:32<00:00, 10.50it/s, loss=0.268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 Summary:\n",
      "  Train Loss: 0.2888\n",
      "  Validation Loss: 0.6381, Accuracy: 0.6515\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "CCModel = CrossCellLineModel(resnext34, cell_type_num=4, device='cuda:1')\n",
    "LR = 1e-4\n",
    "EPOCHS = 20\n",
    "train(CCModel, train_loader, test_loader, LR, EPOCHS, device='cuda:1')\n",
    "torch.save(CCModel,'NVWACE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15a76604-3de0-4871-abc4-71a4f9fc1b02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 172/172 [00:02<00:00, 68.15it/s]\n"
     ]
    }
   ],
   "source": [
    "CCModel = torch.load('NVWACE.pth',weights_only=False)\n",
    "valid_predictions = predict(CCModel, valid_loader, 'cuda:1')\n",
    "predicted_classes = torch.where(valid_predictions>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a1bd709-f98f-4169-958c-7718708bb7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7219\n",
      "MCC: 0.3169\n",
      "F1 Score: 0.6243\n",
      "Accuracy: 0.6566\n",
      "Recall: 0.5732\n",
      "Precision: 0.6854\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions = valid_predictions;labels = Y_valid\n",
    "predicted_labels = [1 if p >= 0.5 else 0 for p in predictions]\n",
    "\n",
    "# 计算指标\n",
    "auc_val = auc(roc_curve(labels, predictions)[0],roc_curve(labels, predictions)[1])\n",
    "mcc = matthews_corrcoef(labels, predicted_labels)\n",
    "f1 = f1_score(labels, predicted_labels)\n",
    "accuracy = accuracy_score(labels, predicted_labels)\n",
    "recall = recall_score(labels, predicted_labels)\n",
    "precision = precision_score(labels, predicted_labels)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"AUC: {auc_val:.4f}\")\n",
    "print(f\"MCC: {mcc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.bar([1,2,3,4,5,6],[auc_val,mcc,f1,accuracy,recall,precision])\n",
    "plt.ylim([0,1])\n",
    "plt.xticks([1,2,3,4,5,6],[\"AUC\",\"MCC\",\"F1 Score\",\"Accuracy\",\"Recall\",\"Precision\"],rotation=-30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689233d4-a4f7-4353-bd4f-8b3edf5a4014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eScreen",
   "language": "python",
   "name": "escreen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
